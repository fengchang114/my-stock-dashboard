import streamlit as st
import pandas as pd
import yfinance as yf
import requests
import urllib3
import io
import time
import datetime as dt

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
st.set_page_config(page_title="æ³•äººé€£çºŒè²·è³£è¶…", layout="wide")

# ==========================================
# ç”¢æ¥­ä»£ç¢¼èˆ‡å·¥å…·å‡½å¼
# ==========================================
INDUSTRY_CODE_MAP = {
    "01": "æ°´æ³¥å·¥æ¥­", "02": "é£Ÿå“å·¥æ¥­", "03": "å¡‘è† å·¥æ¥­", "04": "ç´¡ç¹”çº–ç¶­",
    "05": "é›»æ©Ÿæ©Ÿæ¢°", "06": "é›»å™¨é›»çºœ", "07": "åŒ–å­¸ç”ŸæŠ€é†«ç™‚", "08": "ç»ç’ƒé™¶ç“·",
    "09": "é€ ç´™å·¥æ¥­", "10": "é‹¼éµå·¥æ¥­", "11": "æ©¡è† å·¥æ¥­", "12": "æ±½è»Šå·¥æ¥­",
    "13": "é›»å­å·¥æ¥­", "14": "å»ºæç‡Ÿé€ ", "15": "èˆªé‹æ¥­", "16": "è§€å…‰é¤æ—…",
    "17": "é‡‘èä¿éšª", "18": "è²¿æ˜“ç™¾è²¨", "19": "ç¶œåˆ", "20": "å…¶ä»–",
    "21": "åŒ–å­¸å·¥æ¥­", "22": "ç”ŸæŠ€é†«ç™‚", "23": "æ²¹é›»ç‡ƒæ°£", "24": "åŠå°é«”æ¥­",
    "25": "é›»è…¦åŠé€±é‚Š", "26": "å…‰é›»æ¥­", "27": "é€šä¿¡ç¶²è·¯", "28": "é›»å­é›¶çµ„ä»¶",
    "29": "é›»å­é€šè·¯", "30": "è³‡è¨Šæœå‹™", "31": "å…¶ä»–é›»å­", "32": "æ–‡åŒ–å‰µæ„",
    "33": "è¾²æ¥­ç§‘æŠ€", "34": "é›»å­å•†å‹™", "35": "ç¶ èƒ½ç’°ä¿", "36": "æ•¸ä½é›²ç«¯",
    "37": "é‹å‹•ä¼‘é–’", "38": "å±…å®¶ç”Ÿæ´»", "80": "ç®¡ç†è‚¡ç¥¨", "91": "å­˜è¨—æ†‘è­‰",
}

def convert_to_float(val):
    try:
        val_str = str(val).strip()
        if val_str in ['-', '', 'nan', 'None']: return 0.0
        return float(val_str.replace(',', ''))
    except: return 0.0

@st.cache_data(ttl=86400)
def get_market_stocks():
    """ç²å–å…¨å¸‚å ´è‚¡ç¥¨æ¸…å–®ï¼Œä¸¦ç›´æ¥æ’é™¤ ETFã€æ¬Šè­‰èˆ‡ -KY"""
    stocks = {}
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    # æŠ“å–ä¸Šå¸‚
    try:
        res = requests.get("https://openapi.twse.com.tw/v1/opendata/t187ap03_L", headers=headers, verify=False, timeout=5).json()
        for row in res:
            code = row.get('å…¬å¸ä»£è™Ÿ', '').strip()
            name = row.get('å…¬å¸ç°¡ç¨±', '').strip()
            ind = INDUSTRY_CODE_MAP.get(row.get('ç”¢æ¥­åˆ¥', ''), 'å…¶ä»–')
            # æ’é™¤æ¢ä»¶: 00é–‹é ­(ETF), é•·åº¦>=6(æ¬Šè­‰), åå­—åŒ…å«KY
            if not code.startswith('00') and len(code) < 6 and 'KY' not in name:
                stocks[code] = {'name': name, 'industry': ind, 'market': 'ä¸Šå¸‚'}
    except: pass
    
    # æŠ“å–ä¸Šæ«ƒ
    try:
        res = requests.get("https://www.tpex.org.tw/openapi/v1/t187ap03_O", headers=headers, verify=False, timeout=5).json()
        for row in res:
            code = row.get('å…¬å¸ä»£è™Ÿ', '').strip()
            name = row.get('å…¬å¸ç°¡ç¨±', '').strip()
            ind = INDUSTRY_CODE_MAP.get(row.get('ç”¢æ¥­åˆ¥', ''), 'å…¶ä»–')
            # æ’é™¤æ¢ä»¶: 00é–‹é ­(ETF), é•·åº¦>=6(æ¬Šè­‰), åå­—åŒ…å«KY
            if not code.startswith('00') and len(code) < 6 and 'KY' not in name:
                stocks[code] = {'name': name, 'industry': ind, 'market': 'ä¸Šæ«ƒ'}
    except: pass
    return stocks

@st.cache_data(ttl=3600)
def get_fundamental_data(target_date):
    fundamental_dict = {}
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    date_str_twse = target_date.strftime('%Y%m%d')
    try:
        res = requests.get(f"https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d?date={date_str_twse}&selectType=ALL&response=json", headers=headers, verify=False).json()
        if res.get('stat') == 'OK':
            for row in res['data']:
                fundamental_dict[str(row[0]).strip()] = {'pe': convert_to_float(row[5]), 'pb': convert_to_float(row[6])}
    except: pass

    roc_year = target_date.year - 1911
    date_str_tpex = f"{roc_year}/{target_date.strftime('%m/%d')}"
    try:
        res = requests.get(f"https://www.tpex.org.tw/web/stock/aftertrading/peratio_analysis/pera_result.php?l=zh-tw&o=json&d={date_str_tpex}", headers=headers, verify=False).json()
        raw = res.get('tables', [{}])[0].get('data', []) or res.get('aaData', [])
        for row in raw:
            fundamental_dict[str(row[0]).strip()] = {'pe': convert_to_float(row[2]), 'pb': convert_to_float(row[6])}
    except: pass
    return fundamental_dict

def get_chip_history(base_date, days_to_fetch=25):
    daily_data, fetched_days, attempts = {}, 0, 0
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    progress_bar = st.progress(0, text="æ­£åœ¨å›æ¨ä¸‹è¼‰ç±Œç¢¼æ­·å²æ•¸æ“š...")

    while fetched_days < days_to_fetch and attempts < 60:
        target_date = base_date - dt.timedelta(days=attempts)
        attempts += 1
        if target_date.weekday() > 4: continue
        
        date_str_twse = target_date.strftime('%Y%m%d')
        roc_year = target_date.year - 1911
        date_str_tpex = f"{roc_year}/{target_date.strftime('%m/%d')}"
        date_display = target_date.strftime('%Y-%m-%d')
        
        progress_bar.progress((fetched_days + 1) / days_to_fetch, text=f"æ­£åœ¨ç²å– {date_display} ç±Œç¢¼...")
        
        day_chips, has_data = {}, False
        try:
            res_twse = requests.get(f"https://www.twse.com.tw/rwd/zh/fund/T86?date={date_str_twse}&selectType=ALL&response=json", timeout=5, verify=False, headers=headers).json()
            if res_twse.get('stat') == 'OK':
                has_data = True
                idx_f = next((i for i, f in enumerate(res_twse['fields']) if 'å¤–é™¸è³‡è²·è³£è¶…è‚¡æ•¸' in f), 4)
                idx_t = next((i for i, f in enumerate(res_twse['fields']) if 'æŠ•ä¿¡è²·è³£è¶…è‚¡æ•¸' in f), 10)
                for row in res_twse['data']:
                    try: day_chips[row[0]] = {'f': int(row[idx_f].replace(',', '')) // 1000, 't': int(row[idx_t].replace(',', '')) // 1000}
                    except: pass
            
            res_tpex = requests.get(f"https://www.tpex.org.tw/web/stock/3insti/daily_trade/3itrade_hedge_result.php?l=zh-tw&o=json&se=AL&t=D&d={date_str_tpex}", timeout=5, verify=False, headers=headers).json()
            rows = res_tpex.get('aaData', []) or res_tpex.get('tables', [{}])[0].get('data', [])
            if rows:
                has_data = True
                for row in rows:
                    try: day_chips[row[0]] = {'f': int(row[10].replace(',', '')) // 1000, 't': int(row[13].replace(',', '')) // 1000}
                    except: pass
                    
            if has_data:
                daily_data[date_display] = day_chips
                fetched_days += 1
            time.sleep(0.2)
        except: pass
        
    progress_bar.empty()
    sorted_dates = sorted(daily_data.keys(), reverse=True)
    chips_history = {}
    all_codes = set()
    for d in daily_data: all_codes.update(daily_data[d].keys())
    for code in all_codes:
        chips_history[code] = [daily_data[d].get(code, {'f': 0, 't': 0}) for d in sorted_dates]
    return chips_history

def calculate_streaks(history_list):
    f_buy = f_sell = t_buy = t_sell = 0
    for day in history_list:
        if day['f'] > 0: f_buy += 1
        else: break
    for day in history_list:
        if day['f'] < 0: f_sell += 1
        else: break
    for day in history_list:
        if day['t'] > 0: t_buy += 1
        else: break
    for day in history_list:
        if day['t'] < 0: t_sell += 1
        else: break
    return f_buy, f_sell, t_buy, t_sell

# ==========================================
# ç¶²é ä¸»ç¨‹å¼
# ==========================================
st.title("ğŸ”¥ æ³•äººé€£çºŒè²·è³£è¶…å…¨å¸‚å ´æƒæ")
st.markdown("è‡ªå‹•æƒæå…¨å¸‚å ´ï¼Œä¸¦å·²**æ’é™¤ ETFã€æ¬Šè­‰èˆ‡ -KY è‚¡**ã€‚")

with st.sidebar:
    st.header("è¨­å®š")
    target_date = st.date_input("é¸æ“‡æŸ¥è©¢æ—¥æœŸ", dt.date.today())
    run_btn = st.button("ğŸš€ é–‹å§‹å…¨å¸‚å ´æƒæ", use_container_width=True)

if run_btn:
    with st.spinner("æ­£åœ¨å–å¾—å…¨å¸‚å ´è‚¡ç¥¨æ¸…å–®..."):
        market_stocks = get_market_stocks()
        
    fund_data = get_fundamental_data(target_date)
    chips_history = get_chip_history(target_date, days_to_fetch=25)
    
    st.info(f"å·²è¼‰å…¥ {len(market_stocks)} æª”ç´”å€‹è‚¡ï¼Œé–‹å§‹é‹ç®—é€£çºŒç±Œç¢¼...")
    
    # --- æ•ˆèƒ½å„ªåŒ–ï¼šåªæŠ“å–æœ‰é€£çºŒè²·è³£è¶…çš„è‚¡ç¥¨è‚¡åƒ¹ ---
    active_codes = []
    stock_streaks = {}
    
    for code, info in market_stocks.items():
        history = chips_history.get(code, [])
        f_buy, f_sell, t_buy, t_sell = calculate_streaks(history)
        max_buy = max(f_buy, t_buy)
        max_sell = max(f_sell, t_sell)
        
        # åªè¦æ³•äººæœ‰å‹•ä½œ(>0)ï¼Œæ‰åŠ å…¥ yfinance ä¸‹è¼‰æ¸…å–®
        if max_buy > 0 or max_sell > 0:
            active_codes.append(code)
            stock_streaks[code] = {
                'f_buy': f_buy, 'f_sell': f_sell, 
                't_buy': t_buy, 't_sell': t_sell,
                'max_buy': max_buy, 'max_sell': max_sell,
                'last_chip': history[0] if history else {'f': 0, 't': 0}
            }

    yf_tickers = []
    for code in active_codes:
        suffix = ".TWO" if market_stocks[code]['market'] == 'ä¸Šæ«ƒ' else ".TW"
        yf_tickers.append(f"{code}{suffix}")

    price_data = {}
    with st.spinner(f"æ­£åœ¨é€é yfinance ä¸‹è¼‰ {len(yf_tickers)} æª”æ´»èºå€‹è‚¡è‚¡åƒ¹èˆ‡å‡é‡..."):
        # æŠ“å–å…©å€‹æœˆè³‡æ–™ç¢ºä¿èƒ½ç®—å‡º MA20
        data = yf.download(yf_tickers, period="2mo", group_by='ticker', threads=True, progress=False, auto_adjust=True)
        for ticker in yf_tickers:
            df = data if len(yf_tickers) == 1 else data.get(ticker, pd.DataFrame())
            if not df.empty:
                df.index = pd.to_datetime(df.index).normalize()
                # ç¢ºä¿åªå–ç›®æ¨™æ—¥æœŸä»¥å‰çš„è³‡æ–™
                df = df[df.index <= pd.Timestamp(target_date)]
                if len(df) > 20: 
                    price_data[ticker.split('.')[0]] = df

    # --- æ•´ç†å ±è¡¨ ---
    buy_list, sell_list = [], []
    
    for code in active_codes:
        info = market_stocks[code]
        streak_info = stock_streaks[code]
        
        df = price_data.get(code, pd.DataFrame())
        close = change = vol = vol_ma5 = ma20 = 0
        if not df.empty:
            last_row = df.iloc[-1]
            close = round(last_row['Close'], 2) if pd.notna(last_row['Close']) else 0
            ma20 = round(df['Close'].rolling(20).mean().iloc[-1], 2)
            vol = int(last_row['Volume'] // 1000)
            vol_ma5 = int(df['Volume'].rolling(5).mean().iloc[-1] // 1000)
            if len(df) >= 2 and df['Close'].iloc[-2] > 0:
                change = round(((close - df['Close'].iloc[-2]) / df['Close'].iloc[-2]) * 100, 2)

        pe_val = fund_data.get(code, {}).get('pe', 0.0)
        pb_val = fund_data.get(code, {}).get('pb', 0.0)
        nav_val = round(close / pb_val, 2) if pb_val > 0 else 0.0

        row_base = {
            "ä»£è™Ÿ": code, 
            "åç¨±": info['name'], 
            "ç”¢æ¥­åˆ¥": info['industry'], 
            "æ”¶ç›¤": close, 
            "æ¼²å¹…%": change,
            "æˆäº¤é‡": vol, 
            "5æ—¥å‡é‡": vol_ma5, 
            "æœ¬ç›Šæ¯”": pe_val, 
            "è‚¡åƒ¹æ·¨å€¼æ¯”": pb_val,
            "æ¯è‚¡æ·¨å€¼": nav_val, 
            "MA20": ma20, 
            "å¤–è³‡": streak_info['last_chip']['f'], 
            "æŠ•ä¿¡": streak_info['last_chip']['t']
        }

        # åˆ†é¡è²·è¶…
        if streak_info['max_buy'] > 0:
            r = row_base.copy()
            f_buy, t_buy = streak_info['f_buy'], streak_info['t_buy']
            if f_buy > 0 and t_buy > 0: desc = f"åœŸæ´‹åŒæ­¥é€£è²· (å¤–{f_buy}/æŠ•{t_buy})"
            elif f_buy > t_buy: desc = f"å¤–è³‡é€£è²· {f_buy} å¤©"
            else: desc = f"æŠ•ä¿¡é€£è²· {t_buy} å¤©"
            r["é€£çºŒå¤©æ•¸"], r["è©³ç´°èªªæ˜"] = streak_info['max_buy'], desc
            buy_list.append(r)

        # åˆ†é¡è³£è¶…
        if streak_info['max_sell'] > 0:
            r = row_base.copy()
            f_sell, t_sell = streak_info['f_sell'], streak_info['t_sell']
            if f_sell > 0 and t_sell > 0: desc = f"åœŸæ´‹åŒæ­¥é€£è³£ (å¤–{f_sell}/æŠ•{t_sell})"
            elif f_sell > t_sell: desc = f"å¤–è³‡é€£è³£ {f_sell} å¤©"
            else: desc = f"æŠ•ä¿¡é€£è³£ {t_sell} å¤©"
            r["é€£çºŒå¤©æ•¸"], r["è©³ç´°èªªæ˜"] = streak_info['max_sell'], desc
            sell_list.append(r)

    cols_order = ["ä»£è™Ÿ", "åç¨±", "ç”¢æ¥­åˆ¥", "æ”¶ç›¤", "æ¼²å¹…%", "æˆäº¤é‡", "5æ—¥å‡é‡", "æœ¬ç›Šæ¯”", "è‚¡åƒ¹æ·¨å€¼æ¯”", "æ¯è‚¡æ·¨å€¼", "MA20", "å¤–è³‡", "æŠ•ä¿¡", "é€£çºŒå¤©æ•¸", "è©³ç´°èªªæ˜"]
    df_buy = pd.DataFrame(buy_list)[cols_order].sort_values(by="é€£çºŒå¤©æ•¸", ascending=False) if buy_list else pd.DataFrame(columns=cols_order)
    df_sell = pd.DataFrame(sell_list)[cols_order].sort_values(by="é€£çºŒå¤©æ•¸", ascending=False) if sell_list else pd.DataFrame(columns=cols_order)

    st.success("âœ… å…¨å¸‚å ´åˆ†æå®Œæˆï¼")
    tab_buy, tab_sell = st.tabs(["ğŸ”¥ é€£çºŒè²·è¶…æ¸…å–®", "ğŸ§Š é€£çºŒè³£è¶…æ¸…å–®"])
    with tab_buy: st.dataframe(df_buy, hide_index=True, use_container_width=True)
    with tab_sell: st.dataframe(df_sell, hide_index=True, use_container_width=True)

    # ç”¢å‡º Excel ä¸‹è¼‰
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_buy.to_excel(writer, sheet_name='æ³•äººé€£çºŒè²·è¶…', index=False)
        df_sell.to_excel(writer, sheet_name='æ³•äººé€£çºŒè³£è¶…', index=False)
    output.seek(0)
    
    st.sidebar.download_button("ğŸ“¥ ä¸‹è¼‰çµæœå ±è¡¨ (Excel)", data=output, file_name=f"{target_date}_æ³•äººé€£çºŒè²·è³£è¶….xlsx", type="primary")